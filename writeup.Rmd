---
title: "Boston Marathon Finish Time Predictions"
subtitle: "Harvard Stats E139 Fall 2015"
author: 
- Nathaniel Burbank
- Pooja Singh
- David Wihl
date: "December 21, 2015"
abstract: |
    We want to build a reasonably accurate model for predicting Boston Marathon finish times based on gender, age on 5k split times. We will build a baseline using untransformed linear regression. Then, we will analyze the data and perform appropriate transformations. After transforming the data, we will cluster the data into different subgroups using unsupervised learning algorithms. Finally, we will run different regression algorithms on the transformed and subsetted data to see our improvements over the baseline.
output: pdf_document
---

## Baseline

We obtained our data from two sources. First, we downloaded a [previously assembled dataset](http://www.stat.unc.edu/faculty/rs/Bostonwebpage/readme.html)  from a group of researchers University of North Carolina-Chapel Hill who [analyzed](http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0093800) historic runner performance with the goal of predicting the anticpated finish times for the approximately 5000 runners who were unable to complete the 2013 Boston Marathon due the bombings at the finish line. This data sat contained that split and finish times for 69923 runners in the 2010, 2011, and 2013 Boston Marathons. (The 2012 Boston marathon was intentionally excluded from their dataset because it was unusually hot that year.) We also obtained finish and split times for 78042 runners who completed the Chicago Marathon in 2014 and 2015. We obtained these results directly from the Chicago Marathonâ€™s [results website](http://results.chicagomarathon.com/2015/)  using a custom python scraper. 


First let's read in the data and calculate finish times:


## Step 1: Baseline Regression

Our baseline mean error is _whatever_, or approximately 15 minutes.


## Step 2: Examination of the data and transformations.

Some preliminary EDA of the data:

The data appears somewhat right skewed. Let's try a log transform of the predicted variable:


That seems better.

Let's try a multiple regression on the log transformed data:


Our transformed mean error is 



Let's plot the residuals vs predicted

This appears to be spreading out and trending up. 

Let's try a polynomial transformation on the 5k time to see if that improves things:

## Step 3: Clustering the Data into Subgroups

Let's try subsetting the data set in subgroups using an unsupervised learning algorithm.



**Note: as you can see, the unsupervised learning found groupings that would have difficult if not
impossible to us to find on our own**

## Conclusion

By transforming and subsetting the data we were able to bring down the size of the residuals significantly and improve the accuracy of the model...

# Appendix A - Code

The following is the code used to prepare this report:
```{r code=readLines(knitr::purl('basecode.Rmd', documentation = 0)), eval = FALSE}

```

# Appendix B - References

[Place R Code in Appendix](http://stackoverflow.com/questions/33485893/create-appendix-with-r-code-in-rmarkdown-knitr)

